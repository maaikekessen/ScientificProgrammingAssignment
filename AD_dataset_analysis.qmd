---
title: "AD_dataset_analysis"
author: "Maaike Kessen"
format: html
editor: visual
---

# Alzheimer’s disease analysis: data analysis

```{r}
#list all required packages
packages <- c(
  "ggplot2", "caret", "tidyverse", "dplyr",
  "pROC", "broom", "gt", "randomForest", "glmnet"
)

#check which are not installed and install them automatically
installed <- packages %in% rownames(installed.packages())
if (any(!installed)) {
  cat("Installing missing packages:\n")
  install.packages(packages[!installed], dependencies = TRUE)
}

#load all packages
invisible(lapply(packages, library, character.only = TRUE))
```

```{r}
#set the working directory
#(change this path to match your local device)
setwd("C:/Users/Maaike/Documents/uni/scientific programming/assignment/ScientificProgrammingAssignment")

# Read the cleaned CSV produced by the cleaning script
# (write.csv creates comma-separated files)
df <- read.csv(
  file = "cleaned_alzheimers_dataset.csv",
  header = TRUE,
  sep = ",",            
  na.strings = "NA",    # write.csv writes NA as "NA" by default
  stringsAsFactors = FALSE
)

#sanity check
str(df)
summary(df)

#set global seed 
set.seed(123)
```

## Define variable blocks

In the code below, I define some blocks that are used later in the analysis, therefore getting rid of redundancies.

```{r}
cognitive_vars <- c("MMSE", "ADL", "FunctionalAssessment")
clinical_vars  <- c("Age", "Gender", "Hypertension", "Diabetes", "Depression")
lifestyle_vars <- c("PhysicalActivity", "DietQuality", "SleepQuality", "AlcoholConsumption")
symptom_vars   <- c("MemoryComplaints", "BehavioralProblems", "Confusion",
                    "Disorientation", "PersonalityChanges", "Forgetfulness",
                    "DifficultyCompletingTasks")

#create a named list for easy iteration in later analyses
blocks <- list(
  Cognitive  = cognitive_vars,
  Clinical   = clinical_vars,
  Lifestyle  = lifestyle_vars,
  Symptoms   = symptom_vars
)
```

## Logistic regression model & ROC analysis

To identify the main factors contributing to Alzheimer's diagnosis, I trained a logistic regression model using all available variables. A stratified train/test split (70/30) ensured that both groups had a similar proportion of Alzheimer’s and non-Alzheimer’s cases.

The model was trained using 5-fold cross-validation to avoid overfitting and estimate generalization performance.

After fitting the model, I examined variable importance, which shows how much each predictor contributes to the classification. As expected, cognitive and functional assessments came up as the most influential predictors.

The confusion matrix below shows how well the model distinguishes between AD and no-AD cases.

```{r}
#confusion matrix
preds_class <- predict(fit_glm, newdata = testData)

#ensure both are factors with the same levels
testData$Diagnosis <- factor(testData$Diagnosis, levels = c("No AD", "AD"))
preds_class <- factor(preds_class, levels = c("No AD", "AD"))

conf_mat <- confusionMatrix(preds_class, testData$Diagnosis, positive = "AD")
conf_mat

#visualize confusion matrix
cm_df <- as.data.frame(conf_mat$table)
colnames(cm_df) <- c("Prediction", "Reference", "Freq")

ggplot(cm_df, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), color = "black", size = 5) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  theme_minimal() +
  labs(
    title = "Confusion Matrix (Full Logistic Model)",
    x = "Actual Diagnosis",
    y = "Predicted Diagnosis",
    fill = "Count"
  )

```

## ROC curve: full model vs risk-only model

To evaluate the predictive performance of the logistic regression model, I compared two versions:

1.  A full model, including all available variables.
2.  A risk-only model, containing only demographic and health-related factors (excluding cognitive tests and symptom variables).

I used ROC (Receiver Operating Characteristic) curves to assess how well each model distinguishes between AD and no-AD cases. The AUC (Area Under the Curve) summarizes overall classification ability. Higher values indicate better discrimination.

The model achieved an AUC of \~0.88, while the risk-only model achieved an AUC of \~0.59, indicating that the inclusion of cognitive and functional assessments dramatically improves predictive performance.

This comparison confirms that biological and lifestyle risk factors alone are not sufficient to distinguish AD patients accurately, whereas cognitive test results provide most of the diagnostic power.

```{r}
#ensure outcome is a factor with correct levels
trainData$Diagnosis <- factor(trainData$Diagnosis, levels = c("No AD", "AD"))
testData$Diagnosis  <- factor(testData$Diagnosis,  levels = c("No AD", "AD"))

#full model predictions
probs_full <- predict(fit_glm, newdata = testData, type = "prob")
roc_full <- roc(
  response = testData$Diagnosis,
  predictor = probs_full$`AD`,
  levels = rev(levels(testData$Diagnosis))
)

#define "risk-only" subset (exclude cognitive + symptom variables) 
exclude_vars <- c(blocks$Cognitive, blocks$Symptoms)
risk_vars <- setdiff(names(df), c("PatientID", "Diagnosis", exclude_vars))

#keep only variables that have variation (no constant factors)
risk_vars_filtered <- risk_vars[
  sapply(trainData[, risk_vars, drop = FALSE], function(x) length(unique(x)) > 1)
]

#build and fit the risk-only model
risk_formula <- as.formula(paste("Diagnosis ~", paste(risk_vars_filtered, collapse = " + ")))
risk_model <- glm(risk_formula, data = trainData, family = binomial)

#predict and compute ROC for risk-only model
pred_probs_risk <- predict(risk_model, newdata = testData, type = "response")
roc_risk <- roc(testData$Diagnosis, pred_probs_risk, levels = c("No AD", "AD"))

#combined ROC plot 
plot(roc_full, col = "steelblue", lwd = 2,
     main = "ROC Curve: Full Model vs. Risk-Only Model",
     legacy.axes = TRUE)
plot(roc_risk, add = TRUE, col = "darkorange", lwd = 2, lty = 2)

legend("bottomright",
       legend = c(
         paste0("Full model (AUC = ", round(auc(roc_full), 3), ")"),
         paste0("Risk-only model (AUC = ", round(auc(roc_risk), 3), ")")
       ),
       col = c("steelblue", "darkorange"),
       lwd = 2, lty = c(1, 2), bty = "n")

#AUC values
auc(roc_full)
auc(roc_risk)

```

## Logistic regression coefficients

To better understand which factors most strongly influence the likelihood of developing Alzheimer’s disease, I fitted a simplified logistic regression model including key demographic, health, and cognitive variables.

The model summary provides log-odds coefficients, where:

-   Positive coefficients indicate higher likelihood of Alzheimer’s diagnosis,

-   Negative coefficients indicate lower likelihood.

The plot below visualizes these coefficients, with stars (`*`) denoting significance levels. All significant coefficients appear to be p\<0.001.

From this analysis:

-   Cognitive measures show strong negative coefficients, meaning that higher scores (better cognitive or functional performance) are associated with lower Alzheimer’s risk.

-   Memory complaints and behavioral problems have large positive coefficients, indicating a higher likelihood of Alzheimer’s diagnosis.

-   Age, gender, and cardiovascular/metabolic factors (e.g., diabetes, hypertension) were not statistically significant in this dataset.

Overall, this regression confirms that clinical cognitive assessments and observable behavioral symptoms are the strongest indicators of Alzheimer’s, aligning with expectations from clinical diagnosis criteria.

```{r}
#ensure Diagnosis is a binary factor with correct level order
df$Diagnosis <- factor(df$Diagnosis, levels = c("No AD", "AD"))

#fit simplified logistic regression model
#includes demographic, health, and cognitive variables
model <- glm(
  Diagnosis ~ Age + Gender + EducationLevel + Depression + 
    Hypertension + Diabetes + MMSE + ADL + FunctionalAssessment + 
    MemoryComplaints + BehavioralProblems, 
  data = df, 
  family = binomial
)

#model summary 
summary(model)

#visualize coefficients (log-odds) with significance stars
tidy(model) %>%
  filter(term != "(Intercept)") %>%    #remove intercept
  mutate(
    Significance = ifelse(
      p.value < 0.001, "***", 
      ifelse(p.value < 0.05, "*", "")
    )
  ) %>%
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = estimate > 0)) +
  geom_col(show.legend = FALSE) +
  geom_text(aes(label = Significance), hjust = -0.2, size = 4) +
  coord_flip() +
  theme_minimal() +
  labs(
    title = "Predictors of Alzheimer's Diagnosis (Logistic Regression)",
    x = "Variable", 
    y = "Coefficient (log-odds)"
  )
```

## Logistic regression results: odds ratios

This table presents the logistic regression coefficients in terms of odds ratios (OR) for easier interpretation.

An OR above 1 indicates a variable is associated with increased odds of Alzheimer’s disease, while an OR below 1 indicates a protective effect.

```{r}
#convert log-odds coefficients into OR with 95% CI
#makes interpretation more intuitive — values >1 increase AD risk, <1 decrease it

#step 1: compute OR and CI
or_table <- tidy(model, conf.int = TRUE, exponentiate = TRUE) %>%
  filter(term != "(Intercept)") %>%  #exclude intercept term
  mutate(
    p_value = ifelse(p.value < 0.001, "<0.001", round(p.value, 3)),  #format p-values
    Effect = case_when(
      estimate > 1 ~ "↑ AD risk",   #odds ratio > 1 = increased risk
      estimate < 1 ~ "↓ AD risk",   #odds ratio < 1 = decreased risk
      TRUE ~ "No effect"
    )
  ) %>%
  select(
    Variable = term,
    `Odds Ratio` = estimate,
    `95% CI Lower` = conf.low,
    `95% CI Upper` = conf.high,
    `p-value` = p_value,
    Effect
  ) %>%
  mutate(across(where(is.numeric), ~ round(., 2)))  #round numeric columns for clarity


#step 2: format as a styled table for easy viewing
or_table_gt <- or_table %>%
  gt() %>%
  tab_header(
    title = md("**Predictors of Alzheimer's Diagnosis**"),
    subtitle = md("Logistic Regression — Odds Ratios with 95% Confidence Intervals")
  ) %>%
  fmt_number(
    columns = c(`Odds Ratio`, `95% CI Lower`, `95% CI Upper`),
    decimals = 2
  ) %>%
  cols_label(
    `Odds Ratio` = "Odds Ratio",
    `95% CI Lower` = "95% CI (Lower)",
    `95% CI Upper` = "95% CI (Upper)",
    `p-value` = "p-value",
    Effect = "Effect Direction"
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(columns = vars(Effect))
  )

or_table_gt

```
