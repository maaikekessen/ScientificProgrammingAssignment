---
title: "AD_dataset_cleaning"
format: html
author: "Maaike Kessen"
editor: visual
---

# Alzheimer’s disease analysis: data cleaning

This notebook is the first of 3 needed for this analysis. This script investigates the data, reformats variables, checks for outliers and performs median imputation. Lastly, it changes all categorical variables into factors.

## Data import and initial inspection

In this section, I load and inspect the Alzheimer’s dataset.\
All potential NA representations are standardized to proper `NA` values, to make sure everything stays consistent.\
The `str()` command helps verify variable types. `colSums(is.na())` and `summary()` provide an overview of missing data and basic descriptive statistics.

```{r}
#set the working directory
#(change this path to match your local device)
setwd("C:/Users/Maaike/Documents/uni/scientific programming/assignment/ScientificProgrammingAssignment")

#load the Alzheimer's dataset
# - use ";" as the separator
# - convert various NA indicators (NaN, N/A, blanks) into proper NA values
# - ensure decimals are correctly interpreted
df <- read.csv(
  "alzheimers_disease_data.csv",
  sep = ";",
  header = TRUE,
  na.strings = c("NaN", "nan", "Nan", "NA", "N/A", "", " "),
  dec = "."
)

#inspect the dataset structure: variable types and first few entries
str(df)

#check for missing values per column
cat("----- Missing values per column -----\n")
print(colSums(is.na(df)))

#display descriptive summary statistics for all variables
cat("----- Summary statistics -----\n")
print(summary(df, maxsum = 10))
```

By investigating the results above, you can see that there are some formatting issues for the numeric variables. Let's fix that first.

## Data cleaning and formatting

In this section, I clean and standardize the dataset’s numeric variables using a function.\
First, it makes sure that any decimal commas are converted to dots for proper numeric recognition. The function also identifies implausible values and rescales them.

Expected biological ranges are defined for each variable, making sure that all data points fall within realistic clinical limits (based on the range descriptions on provided Kaggle).\
Finally, I removed the confidential `DoctorInCharge` column, as it contains no analytic value.

```{r}
#the function below will clean the numeric variables
# - replaces commas with dots for decimal consistency
# - converts character values to numeric
# - corrects implausible values by rescaling
fix_variable <- function(x, min_val, max_val) {
  #replace commas with dots for consistent decimal formatting
  x <- gsub(",", ".", as.character(x))
  
  #convert to numeric
  x <- as.numeric(x)
  
  #rescale implausible values 
  x <- sapply(x, function(val) {
    if (is.na(val)) return(NA)
    while (val > max_val) {
      val <- val / 10
    }
    return(val)
  })
  
  return(as.numeric(x))
}

#define expected valid ranges for all numeric variables
#these thresholds are based on the ranges given on Kaggle, where the dataset is downloaded from
ranges <- list(
  Age = c(60, 90),
  BMI = c(15, 40),
  AlcoholConsumption = c(0, 20),
  PhysicalActivity = c(0, 10),
  DietQuality = c(0, 10),
  SleepQuality = c(4, 10),
  SystolicBP = c(90, 180),
  DiastolicBP = c(60, 120),
  CholesterolTotal = c(150, 300),
  CholesterolLDL = c(50, 200),
  CholesterolHDL = c(20, 100),
  CholesterolTriglycerides = c(50, 400),
  MMSE = c(0, 30),
  FunctionalAssessment = c(0, 10),
  ADL = c(0, 10)
)

#apply cleaning function across all defined numeric variables
for (var in names(ranges)) {
  if (var %in% names(df)) {
    df[[var]] <- fix_variable(
      df[[var]],
      min_val = ranges[[var]][1],
      max_val = ranges[[var]][2]
    )
  }
}

#remove DoctorInCharge column as it contains no usable information
df$DoctorInCharge <- NULL

#verify corrected value ranges for numeric variables
sapply(df[names(ranges)], function(x) range(x, na.rm = TRUE))
```

## Data validation after cleaning

```{r}
#inspect the data structure again to verify that:
# - numeric variables are properly formatted as numeric
# - factor variables remain categorical
# - implausible or out-of-range values were corrected
str(df)

#check for missing values after cleaning
cat("------------------------------------------------------------\n")
cat("Missing values per column:\n")
print(colSums(is.na(df)))

#display updated descriptive statistics for all variables
cat("------------------------------------------------------------\n")
cat("Summary statistics:\n")
print(summary(df))
```

## Outlier detection

In this section, I detect potential outliers by checking whether values fall outside the expected ranges defined earlier.\
For each numeric variable, the code returns the patient ID and the variable where the issue occurred.

```{r}
#the function below is used to identify out-of-range values
#returns the Patient ID, variable name, and the offending value
find_outliers <- function(df, var, min_val, max_val) {
  bad_rows <- which(df[[var]] < min_val | df[[var]] > max_val)
  if (length(bad_rows) > 0) {
    data.frame(
      PatientID = df$PatientID[bad_rows],
      Variable = var,
      Value = df[[var]][bad_rows],
      Row = bad_rows
    )
  } else {
    NULL
  }
}

#apply the outlier detection function across all previously defined ranges
outlier_report <- do.call(
  rbind,
  lapply(names(ranges), function(v)
    find_outliers(df, v, ranges[[v]][1], ranges[[v]][2]))
)

#display rows containing out-of-range values
outlier_report
```

## Manual correction of outliers

```{r}
#replace identified corrupted or implausible entries with NA
df$BMI[df$PatientID == 6792] <- NA
df$SleepQuality[df$PatientID == 6644] <- NA
df$CholesterolLDL[df$PatientID == 5186] <- NA
df$CholesterolTriglycerides[df$PatientID == 6485] <- NA
df$FunctionalAssessment[df$PatientID == 6423] <- NA
df$ADL[df$PatientID == 6424] <- NA
```

## Median imputation for missing numeric variables

In this step, I perform median imputation for all numeric variables.\
After identifying and setting corrupted or implausible entries to `NA`, missing values are replaced with the median of each respective column.

Using the median (instead of the mean) is particularly appropriate for clinical or biological datasets, because it reduces the influence of extreme values and maintains the central tendency of the data. Furthermore, since there were so little missing values, the effect it has is negligible.

Finally, `colSums(is.na(df))` is used to verify that no missing values remain, ensuring the dataset is complete and ready for statistical analysis and modeling.

```{r}
#replace missing values in all numeric variables with the median of that variable
#median imputation is robust to outliers and preserves the overall distribution
for (col in names(df)) {
  if (is.numeric(df[[col]])) {
    if (any(is.na(df[[col]]))) {
      median_val <- median(df[[col]], na.rm = TRUE)
      df[[col]][is.na(df[[col]])] <- median_val
    }
  }
}

#verify that no missing values remain in the dataset
colSums(is.na(df))
```

## Convert categorical variables into factors with descriptive labels

In this step, I convert all categorical variables into factors with meaningful labels, improving readability and and making sure the data is compatible with R’s modeling functions.

Many variables in the dataset were encoded as numeric 0/1 indicators.\
By converting these to factors with `"Yes"`/`"No"` labels, I preserve their categorical nature and make visualizations and model outputs more interpretable.

Similarly, demographic variables are converted into labeled factors for better understanding.\
Finally, the *Diagnosis* variable is renamed to `"No AD"` / `"AD"` to clearly reflect Alzheimer’s status in subsequent analyses.

```{r}
#convert demographic and educational variables
if ("Gender" %in% names(df))
  df$Gender <- factor(df$Gender, levels = c(0, 1), labels = c("Male", "Female"))

if ("Ethnicity" %in% names(df))
  df$Ethnicity <- factor(df$Ethnicity, levels = c(0, 1, 2, 3),
                         labels = c("Caucasian", "African American", "Asian", "Other"))

if ("EducationLevel" %in% names(df))
  df$EducationLevel <- factor(df$EducationLevel, levels = 0:3,
                              labels = c("None", "High School", "Bachelor", "Higher"))

#convert all binary clinical and symptom-related variables (0/1) into factors
bin_vars <- c("Smoking", "FamilyHistoryAlzheimers", "CardiovascularDisease", "Diabetes", "Depression",
              "HeadInjury", "Hypertension", "MemoryComplaints", "BehavioralProblems", "Confusion",
              "Disorientation", "PersonalityChanges", "DifficultyCompletingTasks", "Forgetfulness", "Diagnosis")

#only convert variables that exist in the dataset
bin_vars <- intersect(bin_vars, names(df))

for (v in bin_vars) {
  df[[v]] <- factor(df[[v]], levels = c(0, 1), labels = c("No", "Yes"))
}

#adjust diagnosis lable
if ("Diagnosis" %in% names(df)) {
  levels(df$Diagnosis) <- c("No AD", "AD")
}

#export cleaned dataset
output_path <- file.path("cleaned_alzheimers_dataset.csv")
write.csv(df, output_path, row.names = FALSE)
```
