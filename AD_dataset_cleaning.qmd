---
title: "AD_dataset_cleaning"
format: html
author: "Maaike Kessen"
editor: visual
---

# Alzheimer’s disease analysis: data cleaning

## Data import and initial inspection

In this section, I load and inspect the Alzheimer’s dataset.\
All potential NA representations are standardized to proper `NA` values, to make sure everything stays consistent.\
The `str()` command helps verify variable types. `colSums(is.na())` and `summary()` provide an overview of missing data and basic descriptive statistics.

```{r}
#set the working directory
#(change this path to match your local device)
setwd("C:/Users/Maaike/Documents/uni/scientific programming/assignment/ScientificProgrammingAssignment")

#load the Alzheimer's dataset
# - use ";" as the separator
# - convert various NA indicators (NaN, N/A, blanks) into proper NA values
# - ensure decimals are correctly interpreted
df <- read.csv(
  "alzheimers_disease_data.csv",
  sep = ";",
  header = TRUE,
  na.strings = c("NaN", "nan", "Nan", "NA", "N/A", "", " "),
  dec = "."
)

#inspect the dataset structure: variable types and first few entries
str(df)

#check for missing values per column
cat("----- Missing values per column -----\n")
print(colSums(is.na(df)))

#display descriptive summary statistics for all variables
cat("----- Summary statistics -----\n")
print(summary(df, maxsum = 10))
```

By investigating the results above, you can see that there are some formatting issues for the numeric variables. Let's fix that first.

## Data cleaning and formatting

In this section, I clean and standardize the dataset’s numeric variables using a function.\
First, it makes sure that any decimal commas are converted to dots for proper numeric recognition. The function also identifies implausible values and rescales them.

Expected biological ranges are defined for each variable, making sure that all data points fall within realistic clinical limits (based on the range descriptions on provided Kaggle).\
Finally, I removed the confidential `DoctorInCharge` column, as it contains no analytic value.

```{r}
#the function below will clean the numeric variables
# - replaces commas with dots for decimal consistency
# - converts character values to numeric
# - corrects implausible values by rescaling
fix_variable <- function(x, min_val, max_val) {
  #replace commas with dots for consistent decimal formatting
  x <- gsub(",", ".", as.character(x))
  
  #convert to numeric
  x <- as.numeric(x)
  
  #rescale implausible values 
  x <- sapply(x, function(val) {
    if (is.na(val)) return(NA)
    while (val > max_val) {
      val <- val / 10
    }
    return(val)
  })
  
  return(as.numeric(x))
}

#define expected valid ranges for all numeric variables
#these thresholds are based on the ranges given on Kaggle, where the dataset is downloaded from
ranges <- list(
  Age = c(60, 90),
  BMI = c(15, 40),
  AlcoholConsumption = c(0, 20),
  PhysicalActivity = c(0, 10),
  DietQuality = c(0, 10),
  SleepQuality = c(4, 10),
  SystolicBP = c(90, 180),
  DiastolicBP = c(60, 120),
  CholesterolTotal = c(150, 300),
  CholesterolLDL = c(50, 200),
  CholesterolHDL = c(20, 100),
  CholesterolTriglycerides = c(50, 400),
  MMSE = c(0, 30),
  FunctionalAssessment = c(0, 10),
  ADL = c(0, 10)
)

#apply cleaning function across all defined numeric variables
for (var in names(ranges)) {
  if (var %in% names(df)) {
    df[[var]] <- fix_variable(
      df[[var]],
      min_val = ranges[[var]][1],
      max_val = ranges[[var]][2]
    )
  }
}

#remove DoctorInCharge column as it contains no usable information
df$DoctorInCharge <- NULL

#verify corrected value ranges for numeric variables
sapply(df[names(ranges)], function(x) range(x, na.rm = TRUE))
```

## Data validation after cleaning

```{r}
#inspect the data structure again to verify that:
# - numeric variables are properly formatted as numeric
# - factor variables remain categorical
# - implausible or out-of-range values were corrected
str(df)

#check for missing values after cleaning
cat("------------------------------------------------------------\n")
cat("Missing values per column:\n")
print(colSums(is.na(df)))

#display updated descriptive statistics for all variables
cat("------------------------------------------------------------\n")
cat("Summary statistics:\n")
print(summary(df))
```

## Outlier detection

In this section, I detect potential outliers by checking whether values fall outside the expected ranges defined earlier.\
For each numeric variable, the code returns the patient ID and the variable where the issue occurred.

```{r}
#the function below is used to identify out-of-range values
#returns the Patient ID, variable name, and the offending value
find_outliers <- function(df, var, min_val, max_val) {
  bad_rows <- which(df[[var]] < min_val | df[[var]] > max_val)
  if (length(bad_rows) > 0) {
    data.frame(
      PatientID = df$PatientID[bad_rows],
      Variable = var,
      Value = df[[var]][bad_rows],
      Row = bad_rows
    )
  } else {
    NULL
  }
}

#apply the outlier detection function across all previously defined ranges
outlier_report <- do.call(
  rbind,
  lapply(names(ranges), function(v)
    find_outliers(df, v, ranges[[v]][1], ranges[[v]][2]))
)

#display rows containing out-of-range values
outlier_report
```
